{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523c2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import image\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69544c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_file = \"./datasets/RandomActsOfPizza/train.json\"\n",
    "data_test_file = \"./datasets/RandomActsOfPizza/test.json\"\n",
    "\n",
    "df_train = pd.read_json(data_train_file)\n",
    "df_test = pd.read_json(data_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eadb14d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>giver_username_if_known</th>\n",
       "      <th>number_of_downvotes_of_request_at_retrieval</th>\n",
       "      <th>number_of_upvotes_of_request_at_retrieval</th>\n",
       "      <th>post_was_edited</th>\n",
       "      <th>request_id</th>\n",
       "      <th>request_number_of_comments_at_retrieval</th>\n",
       "      <th>request_text</th>\n",
       "      <th>request_text_edit_aware</th>\n",
       "      <th>request_title</th>\n",
       "      <th>requester_account_age_in_days_at_request</th>\n",
       "      <th>...</th>\n",
       "      <th>requester_received_pizza</th>\n",
       "      <th>requester_subreddits_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_retrieval</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_retrieval</th>\n",
       "      <th>requester_user_flair</th>\n",
       "      <th>requester_username</th>\n",
       "      <th>unix_timestamp_of_request</th>\n",
       "      <th>unix_timestamp_of_request_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_l25d7</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi I am in need of food for my 4 children we a...</td>\n",
       "      <td>Hi I am in need of food for my 4 children we a...</td>\n",
       "      <td>Request Colorado Springs Help Us Please</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>nickylvst</td>\n",
       "      <td>1317852607</td>\n",
       "      <td>1317849007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_rcb83</td>\n",
       "      <td>0</td>\n",
       "      <td>I spent the last money I had on gas today. Im ...</td>\n",
       "      <td>I spent the last money I had on gas today. Im ...</td>\n",
       "      <td>[Request] California, No cash and I could use ...</td>\n",
       "      <td>501.111100</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[AskReddit, Eve, IAmA, MontereyBay, RandomKind...</td>\n",
       "      <td>34</td>\n",
       "      <td>4258</td>\n",
       "      <td>116</td>\n",
       "      <td>11168</td>\n",
       "      <td>None</td>\n",
       "      <td>fohacidal</td>\n",
       "      <td>1332652424</td>\n",
       "      <td>1332648824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_lpu5j</td>\n",
       "      <td>0</td>\n",
       "      <td>My girlfriend decided it would be a good idea ...</td>\n",
       "      <td>My girlfriend decided it would be a good idea ...</td>\n",
       "      <td>[Request] Hungry couple in Dundee, Scotland wo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>jacquibatman7</td>\n",
       "      <td>1319650094</td>\n",
       "      <td>1319646494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_mxvj3</td>\n",
       "      <td>4</td>\n",
       "      <td>It's cold, I'n hungry, and to be completely ho...</td>\n",
       "      <td>It's cold, I'n hungry, and to be completely ho...</td>\n",
       "      <td>[Request] In Canada (Ontario), just got home f...</td>\n",
       "      <td>6.518438</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[AskReddit, DJs, IAmA, Random_Acts_Of_Pizza]</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "      <td>None</td>\n",
       "      <td>4on_the_floor</td>\n",
       "      <td>1322855434</td>\n",
       "      <td>1322855434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N/A</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_1i6486</td>\n",
       "      <td>5</td>\n",
       "      <td>hey guys:\\n I love this sub. I think it's grea...</td>\n",
       "      <td>hey guys:\\n I love this sub. I think it's grea...</td>\n",
       "      <td>[Request] Old friend coming to visit. Would LO...</td>\n",
       "      <td>162.063252</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[GayBrosWeightLoss, RandomActsOfCookies, Rando...</td>\n",
       "      <td>1121</td>\n",
       "      <td>1225</td>\n",
       "      <td>1733</td>\n",
       "      <td>1887</td>\n",
       "      <td>None</td>\n",
       "      <td>Futuredogwalker</td>\n",
       "      <td>1373657691</td>\n",
       "      <td>1373654091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  giver_username_if_known  number_of_downvotes_of_request_at_retrieval  \\\n",
       "0                     N/A                                            0   \n",
       "1                     N/A                                            2   \n",
       "2                     N/A                                            0   \n",
       "3                     N/A                                            0   \n",
       "4                     N/A                                            6   \n",
       "\n",
       "   number_of_upvotes_of_request_at_retrieval  post_was_edited request_id  \\\n",
       "0                                          1                0   t3_l25d7   \n",
       "1                                          5                0   t3_rcb83   \n",
       "2                                          3                0   t3_lpu5j   \n",
       "3                                          1                1   t3_mxvj3   \n",
       "4                                          6                0  t3_1i6486   \n",
       "\n",
       "   request_number_of_comments_at_retrieval  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        4   \n",
       "4                                        5   \n",
       "\n",
       "                                        request_text  \\\n",
       "0  Hi I am in need of food for my 4 children we a...   \n",
       "1  I spent the last money I had on gas today. Im ...   \n",
       "2  My girlfriend decided it would be a good idea ...   \n",
       "3  It's cold, I'n hungry, and to be completely ho...   \n",
       "4  hey guys:\\n I love this sub. I think it's grea...   \n",
       "\n",
       "                             request_text_edit_aware  \\\n",
       "0  Hi I am in need of food for my 4 children we a...   \n",
       "1  I spent the last money I had on gas today. Im ...   \n",
       "2  My girlfriend decided it would be a good idea ...   \n",
       "3  It's cold, I'n hungry, and to be completely ho...   \n",
       "4  hey guys:\\n I love this sub. I think it's grea...   \n",
       "\n",
       "                                       request_title  \\\n",
       "0            Request Colorado Springs Help Us Please   \n",
       "1  [Request] California, No cash and I could use ...   \n",
       "2  [Request] Hungry couple in Dundee, Scotland wo...   \n",
       "3  [Request] In Canada (Ontario), just got home f...   \n",
       "4  [Request] Old friend coming to visit. Would LO...   \n",
       "\n",
       "   requester_account_age_in_days_at_request  ...  requester_received_pizza  \\\n",
       "0                                  0.000000  ...                     False   \n",
       "1                                501.111100  ...                     False   \n",
       "2                                  0.000000  ...                     False   \n",
       "3                                  6.518438  ...                     False   \n",
       "4                                162.063252  ...                     False   \n",
       "\n",
       "                     requester_subreddits_at_request  \\\n",
       "0                                                 []   \n",
       "1  [AskReddit, Eve, IAmA, MontereyBay, RandomKind...   \n",
       "2                                                 []   \n",
       "3       [AskReddit, DJs, IAmA, Random_Acts_Of_Pizza]   \n",
       "4  [GayBrosWeightLoss, RandomActsOfCookies, Rando...   \n",
       "\n",
       "   requester_upvotes_minus_downvotes_at_request  \\\n",
       "0                                             0   \n",
       "1                                            34   \n",
       "2                                             0   \n",
       "3                                            54   \n",
       "4                                          1121   \n",
       "\n",
       "   requester_upvotes_minus_downvotes_at_retrieval  \\\n",
       "0                                               1   \n",
       "1                                            4258   \n",
       "2                                               3   \n",
       "3                                              59   \n",
       "4                                            1225   \n",
       "\n",
       "   requester_upvotes_plus_downvotes_at_request  \\\n",
       "0                                            0   \n",
       "1                                          116   \n",
       "2                                            0   \n",
       "3                                           76   \n",
       "4                                         1733   \n",
       "\n",
       "   requester_upvotes_plus_downvotes_at_retrieval  requester_user_flair  \\\n",
       "0                                              1                  None   \n",
       "1                                          11168                  None   \n",
       "2                                              3                  None   \n",
       "3                                             81                  None   \n",
       "4                                           1887                  None   \n",
       "\n",
       "   requester_username  unix_timestamp_of_request  \\\n",
       "0           nickylvst                 1317852607   \n",
       "1           fohacidal                 1332652424   \n",
       "2       jacquibatman7                 1319650094   \n",
       "3       4on_the_floor                 1322855434   \n",
       "4     Futuredogwalker                 1373657691   \n",
       "\n",
       "   unix_timestamp_of_request_utc  \n",
       "0                     1317849007  \n",
       "1                     1332648824  \n",
       "2                     1319646494  \n",
       "3                     1322855434  \n",
       "4                     1373654091  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8454a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_downvotes_of_request_at_retrieval</th>\n",
       "      <th>number_of_upvotes_of_request_at_retrieval</th>\n",
       "      <th>post_was_edited</th>\n",
       "      <th>request_number_of_comments_at_retrieval</th>\n",
       "      <th>requester_account_age_in_days_at_request</th>\n",
       "      <th>requester_account_age_in_days_at_retrieval</th>\n",
       "      <th>requester_days_since_first_post_on_raop_at_request</th>\n",
       "      <th>requester_days_since_first_post_on_raop_at_retrieval</th>\n",
       "      <th>requester_number_of_comments_at_request</th>\n",
       "      <th>requester_number_of_comments_at_retrieval</th>\n",
       "      <th>...</th>\n",
       "      <th>requester_number_of_posts_at_retrieval</th>\n",
       "      <th>requester_number_of_posts_on_raop_at_request</th>\n",
       "      <th>requester_number_of_posts_on_raop_at_retrieval</th>\n",
       "      <th>requester_number_of_subreddits_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_retrieval</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_retrieval</th>\n",
       "      <th>unix_timestamp_of_request</th>\n",
       "      <th>unix_timestamp_of_request_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4.040000e+03</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>4.040000e+03</td>\n",
       "      <td>4.040000e+03</td>\n",
       "      <td>4.040000e+03</td>\n",
       "      <td>4.040000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.424505</td>\n",
       "      <td>6.180446</td>\n",
       "      <td>1.005868e+08</td>\n",
       "      <td>2.871040</td>\n",
       "      <td>254.586579</td>\n",
       "      <td>757.692720</td>\n",
       "      <td>16.417034</td>\n",
       "      <td>518.993205</td>\n",
       "      <td>115.098267</td>\n",
       "      <td>289.425743</td>\n",
       "      <td>...</td>\n",
       "      <td>41.151733</td>\n",
       "      <td>0.063614</td>\n",
       "      <td>1.239109</td>\n",
       "      <td>18.076733</td>\n",
       "      <td>1160.079950</td>\n",
       "      <td>2720.342079</td>\n",
       "      <td>3.743236e+03</td>\n",
       "      <td>7.788069e+03</td>\n",
       "      <td>1.342829e+09</td>\n",
       "      <td>1.342826e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.023101</td>\n",
       "      <td>10.746320</td>\n",
       "      <td>3.558566e+08</td>\n",
       "      <td>4.723339</td>\n",
       "      <td>303.275730</td>\n",
       "      <td>333.035728</td>\n",
       "      <td>70.651428</td>\n",
       "      <td>267.872623</td>\n",
       "      <td>193.318968</td>\n",
       "      <td>357.416133</td>\n",
       "      <td>...</td>\n",
       "      <td>80.798543</td>\n",
       "      <td>0.325773</td>\n",
       "      <td>0.603083</td>\n",
       "      <td>21.736465</td>\n",
       "      <td>3718.365515</td>\n",
       "      <td>6264.378878</td>\n",
       "      <td>2.583816e+04</td>\n",
       "      <td>3.916741e+04</td>\n",
       "      <td>2.333057e+07</td>\n",
       "      <td>2.332989e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.291562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.297723e+09</td>\n",
       "      <td>1.297723e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.473168</td>\n",
       "      <td>522.248455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>279.009051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>1.320469e+09</td>\n",
       "      <td>1.320466e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>157.067170</td>\n",
       "      <td>753.270874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>528.781939</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>174.500000</td>\n",
       "      <td>708.000000</td>\n",
       "      <td>3.510000e+02</td>\n",
       "      <td>1.283500e+03</td>\n",
       "      <td>1.342565e+09</td>\n",
       "      <td>1.342561e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>390.092653</td>\n",
       "      <td>900.349838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>776.226670</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1163.750000</td>\n",
       "      <td>3304.000000</td>\n",
       "      <td>2.303750e+03</td>\n",
       "      <td>6.829000e+03</td>\n",
       "      <td>1.364618e+09</td>\n",
       "      <td>1.364614e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>1.380909e+09</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>2809.750787</td>\n",
       "      <td>2879.276319</td>\n",
       "      <td>785.457685</td>\n",
       "      <td>1025.407593</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>155010.000000</td>\n",
       "      <td>223708.000000</td>\n",
       "      <td>1.286864e+06</td>\n",
       "      <td>2.046482e+06</td>\n",
       "      <td>1.381552e+09</td>\n",
       "      <td>1.381523e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_downvotes_of_request_at_retrieval  \\\n",
       "count                                  4040.000000   \n",
       "mean                                      2.424505   \n",
       "std                                       3.023101   \n",
       "min                                       0.000000   \n",
       "25%                                       1.000000   \n",
       "50%                                       2.000000   \n",
       "75%                                       3.000000   \n",
       "max                                      47.000000   \n",
       "\n",
       "       number_of_upvotes_of_request_at_retrieval  post_was_edited  \\\n",
       "count                                4040.000000     4.040000e+03   \n",
       "mean                                    6.180446     1.005868e+08   \n",
       "std                                    10.746320     3.558566e+08   \n",
       "min                                     0.000000     0.000000e+00   \n",
       "25%                                     2.000000     0.000000e+00   \n",
       "50%                                     4.000000     0.000000e+00   \n",
       "75%                                     7.000000     0.000000e+00   \n",
       "max                                   345.000000     1.380909e+09   \n",
       "\n",
       "       request_number_of_comments_at_retrieval  \\\n",
       "count                              4040.000000   \n",
       "mean                                  2.871040   \n",
       "std                                   4.723339   \n",
       "min                                   0.000000   \n",
       "25%                                   0.000000   \n",
       "50%                                   1.000000   \n",
       "75%                                   4.000000   \n",
       "max                                  61.000000   \n",
       "\n",
       "       requester_account_age_in_days_at_request  \\\n",
       "count                               4040.000000   \n",
       "mean                                 254.586579   \n",
       "std                                  303.275730   \n",
       "min                                    0.000000   \n",
       "25%                                    3.473168   \n",
       "50%                                  157.067170   \n",
       "75%                                  390.092653   \n",
       "max                                 2809.750787   \n",
       "\n",
       "       requester_account_age_in_days_at_retrieval  \\\n",
       "count                                 4040.000000   \n",
       "mean                                   757.692720   \n",
       "std                                    333.035728   \n",
       "min                                     45.291562   \n",
       "25%                                    522.248455   \n",
       "50%                                    753.270874   \n",
       "75%                                    900.349838   \n",
       "max                                   2879.276319   \n",
       "\n",
       "       requester_days_since_first_post_on_raop_at_request  \\\n",
       "count                                        4040.000000    \n",
       "mean                                           16.417034    \n",
       "std                                            70.651428    \n",
       "min                                             0.000000    \n",
       "25%                                             0.000000    \n",
       "50%                                             0.000000    \n",
       "75%                                             0.000000    \n",
       "max                                           785.457685    \n",
       "\n",
       "       requester_days_since_first_post_on_raop_at_retrieval  \\\n",
       "count                                        4040.000000      \n",
       "mean                                          518.993205      \n",
       "std                                           267.872623      \n",
       "min                                             0.000000      \n",
       "25%                                           279.009051      \n",
       "50%                                           528.781939      \n",
       "75%                                           776.226670      \n",
       "max                                          1025.407593      \n",
       "\n",
       "       requester_number_of_comments_at_request  \\\n",
       "count                              4040.000000   \n",
       "mean                                115.098267   \n",
       "std                                 193.318968   \n",
       "min                                   0.000000   \n",
       "25%                                   0.000000   \n",
       "50%                                  24.000000   \n",
       "75%                                 140.250000   \n",
       "max                                 994.000000   \n",
       "\n",
       "       requester_number_of_comments_at_retrieval  ...  \\\n",
       "count                                4040.000000  ...   \n",
       "mean                                  289.425743  ...   \n",
       "std                                   357.416133  ...   \n",
       "min                                     0.000000  ...   \n",
       "25%                                     8.000000  ...   \n",
       "50%                                   114.000000  ...   \n",
       "75%                                   479.000000  ...   \n",
       "max                                  1000.000000  ...   \n",
       "\n",
       "       requester_number_of_posts_at_retrieval  \\\n",
       "count                             4040.000000   \n",
       "mean                                41.151733   \n",
       "std                                 80.798543   \n",
       "min                                  0.000000   \n",
       "25%                                  2.000000   \n",
       "50%                                 13.000000   \n",
       "75%                                 46.000000   \n",
       "max                                999.000000   \n",
       "\n",
       "       requester_number_of_posts_on_raop_at_request  \\\n",
       "count                                   4040.000000   \n",
       "mean                                       0.063614   \n",
       "std                                        0.325773   \n",
       "min                                        0.000000   \n",
       "25%                                        0.000000   \n",
       "50%                                        0.000000   \n",
       "75%                                        0.000000   \n",
       "max                                        5.000000   \n",
       "\n",
       "       requester_number_of_posts_on_raop_at_retrieval  \\\n",
       "count                                     4040.000000   \n",
       "mean                                         1.239109   \n",
       "std                                          0.603083   \n",
       "min                                          0.000000   \n",
       "25%                                          1.000000   \n",
       "50%                                          1.000000   \n",
       "75%                                          1.000000   \n",
       "max                                          9.000000   \n",
       "\n",
       "       requester_number_of_subreddits_at_request  \\\n",
       "count                                4040.000000   \n",
       "mean                                   18.076733   \n",
       "std                                    21.736465   \n",
       "min                                     0.000000   \n",
       "25%                                     1.000000   \n",
       "50%                                    11.000000   \n",
       "75%                                    27.000000   \n",
       "max                                   186.000000   \n",
       "\n",
       "       requester_upvotes_minus_downvotes_at_request  \\\n",
       "count                                   4040.000000   \n",
       "mean                                    1160.079950   \n",
       "std                                     3718.365515   \n",
       "min                                     -173.000000   \n",
       "25%                                        3.000000   \n",
       "50%                                      174.500000   \n",
       "75%                                     1163.750000   \n",
       "max                                   155010.000000   \n",
       "\n",
       "       requester_upvotes_minus_downvotes_at_retrieval  \\\n",
       "count                                     4040.000000   \n",
       "mean                                      2720.342079   \n",
       "std                                       6264.378878   \n",
       "min                                       -173.000000   \n",
       "25%                                         22.000000   \n",
       "50%                                        708.000000   \n",
       "75%                                       3304.000000   \n",
       "max                                     223708.000000   \n",
       "\n",
       "       requester_upvotes_plus_downvotes_at_request  \\\n",
       "count                                 4.040000e+03   \n",
       "mean                                  3.743236e+03   \n",
       "std                                   2.583816e+04   \n",
       "min                                   0.000000e+00   \n",
       "25%                                   9.000000e+00   \n",
       "50%                                   3.510000e+02   \n",
       "75%                                   2.303750e+03   \n",
       "max                                   1.286864e+06   \n",
       "\n",
       "       requester_upvotes_plus_downvotes_at_retrieval  \\\n",
       "count                                   4.040000e+03   \n",
       "mean                                    7.788069e+03   \n",
       "std                                     3.916741e+04   \n",
       "min                                     0.000000e+00   \n",
       "25%                                     5.200000e+01   \n",
       "50%                                     1.283500e+03   \n",
       "75%                                     6.829000e+03   \n",
       "max                                     2.046482e+06   \n",
       "\n",
       "       unix_timestamp_of_request  unix_timestamp_of_request_utc  \n",
       "count               4.040000e+03                   4.040000e+03  \n",
       "mean                1.342829e+09                   1.342826e+09  \n",
       "std                 2.333057e+07                   2.332989e+07  \n",
       "min                 1.297723e+09                   1.297723e+09  \n",
       "25%                 1.320469e+09                   1.320466e+09  \n",
       "50%                 1.342565e+09                   1.342561e+09  \n",
       "75%                 1.364618e+09                   1.364614e+09  \n",
       "max                 1.381552e+09                   1.381523e+09  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9791d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4040 entries, 0 to 4039\n",
      "Data columns (total 32 columns):\n",
      " #   Column                                                Non-Null Count  Dtype  \n",
      "---  ------                                                --------------  -----  \n",
      " 0   giver_username_if_known                               4040 non-null   object \n",
      " 1   number_of_downvotes_of_request_at_retrieval           4040 non-null   int64  \n",
      " 2   number_of_upvotes_of_request_at_retrieval             4040 non-null   int64  \n",
      " 3   post_was_edited                                       4040 non-null   int64  \n",
      " 4   request_id                                            4040 non-null   object \n",
      " 5   request_number_of_comments_at_retrieval               4040 non-null   int64  \n",
      " 6   request_text                                          4040 non-null   object \n",
      " 7   request_text_edit_aware                               4040 non-null   object \n",
      " 8   request_title                                         4040 non-null   object \n",
      " 9   requester_account_age_in_days_at_request              4040 non-null   float64\n",
      " 10  requester_account_age_in_days_at_retrieval            4040 non-null   float64\n",
      " 11  requester_days_since_first_post_on_raop_at_request    4040 non-null   float64\n",
      " 12  requester_days_since_first_post_on_raop_at_retrieval  4040 non-null   float64\n",
      " 13  requester_number_of_comments_at_request               4040 non-null   int64  \n",
      " 14  requester_number_of_comments_at_retrieval             4040 non-null   int64  \n",
      " 15  requester_number_of_comments_in_raop_at_request       4040 non-null   int64  \n",
      " 16  requester_number_of_comments_in_raop_at_retrieval     4040 non-null   int64  \n",
      " 17  requester_number_of_posts_at_request                  4040 non-null   int64  \n",
      " 18  requester_number_of_posts_at_retrieval                4040 non-null   int64  \n",
      " 19  requester_number_of_posts_on_raop_at_request          4040 non-null   int64  \n",
      " 20  requester_number_of_posts_on_raop_at_retrieval        4040 non-null   int64  \n",
      " 21  requester_number_of_subreddits_at_request             4040 non-null   int64  \n",
      " 22  requester_received_pizza                              4040 non-null   bool   \n",
      " 23  requester_subreddits_at_request                       4040 non-null   object \n",
      " 24  requester_upvotes_minus_downvotes_at_request          4040 non-null   int64  \n",
      " 25  requester_upvotes_minus_downvotes_at_retrieval        4040 non-null   int64  \n",
      " 26  requester_upvotes_plus_downvotes_at_request           4040 non-null   int64  \n",
      " 27  requester_upvotes_plus_downvotes_at_retrieval         4040 non-null   int64  \n",
      " 28  requester_user_flair                                  994 non-null    object \n",
      " 29  requester_username                                    4040 non-null   object \n",
      " 30  unix_timestamp_of_request                             4040 non-null   int64  \n",
      " 31  unix_timestamp_of_request_utc                         4040 non-null   int64  \n",
      "dtypes: bool(1), float64(4), int64(19), object(8)\n",
      "memory usage: 982.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#drop  requester_user_flair ,giver_username_if_known\n",
    "#data leak:1,2,4\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e87535ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>request_title</th>\n",
       "      <th>request_text_edit_aware</th>\n",
       "      <th>requester_received_pizza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_l25d7</td>\n",
       "      <td>Request Colorado Springs Help Us Please</td>\n",
       "      <td>Hi I am in need of food for my 4 children we a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_rcb83</td>\n",
       "      <td>[Request] California, No cash and I could use ...</td>\n",
       "      <td>I spent the last money I had on gas today. Im ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_lpu5j</td>\n",
       "      <td>[Request] Hungry couple in Dundee, Scotland wo...</td>\n",
       "      <td>My girlfriend decided it would be a good idea ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_mxvj3</td>\n",
       "      <td>[Request] In Canada (Ontario), just got home f...</td>\n",
       "      <td>It's cold, I'n hungry, and to be completely ho...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_1i6486</td>\n",
       "      <td>[Request] Old friend coming to visit. Would LO...</td>\n",
       "      <td>hey guys:\\n I love this sub. I think it's grea...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  request_id                                      request_title  \\\n",
       "0   t3_l25d7            Request Colorado Springs Help Us Please   \n",
       "1   t3_rcb83  [Request] California, No cash and I could use ...   \n",
       "2   t3_lpu5j  [Request] Hungry couple in Dundee, Scotland wo...   \n",
       "3   t3_mxvj3  [Request] In Canada (Ontario), just got home f...   \n",
       "4  t3_1i6486  [Request] Old friend coming to visit. Would LO...   \n",
       "\n",
       "                             request_text_edit_aware  requester_received_pizza  \n",
       "0  Hi I am in need of food for my 4 children we a...                     False  \n",
       "1  I spent the last money I had on gas today. Im ...                     False  \n",
       "2  My girlfriend decided it would be a good idea ...                     False  \n",
       "3  It's cold, I'n hungry, and to be completely ho...                     False  \n",
       "4  hey guys:\\n I love this sub. I think it's grea...                     False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df_train[['request_id', 'request_title', \n",
    "               'request_text_edit_aware', \n",
    "               'requester_received_pizza']]\n",
    "\n",
    "\n",
    "df_test=df_test[['request_id', 'request_title', \n",
    "               'request_text_edit_aware']]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27292909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "train, valid = train_test_split(df_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1ebc112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/christianapantelidou/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/christianapantelidou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/christianapantelidou/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/christianapantelidou/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re # regular expressions\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords,brown\n",
    "\n",
    "len(brown.words()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88be7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "# `pos_tag` takes the tokenized sentence as input, i.e. list of string,\n",
    "# and returns a tuple of (word, tg), i.e. list of tuples of strings\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "wnl = WordNetLemmatizer() #gives the stem of a word\n",
    "\n",
    "\n",
    "stopwords_json = {\"en\":[\"a\",\"a's\",\"able\",\"about\",\"above\",\"according\",\"accordingly\",\"across\",\"actually\",\"after\",\"afterwards\",\"again\",\"against\",\"ain't\",\"all\",\"allow\",\"allows\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"am\",\"among\",\"amongst\",\"an\",\"and\",\"another\",\"any\",\"anybody\",\"anyhow\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"are\",\"aren't\",\"around\",\"as\",\"aside\",\"ask\",\"asking\",\"associated\",\"at\",\"available\",\"away\",\"awfully\",\"b\",\"be\",\"became\",\"because\",\"become\",\"becomes\",\"becoming\",\"been\",\"before\",\"beforehand\",\"behind\",\"being\",\"believe\",\"below\",\"beside\",\"besides\",\"best\",\"better\",\"between\",\"beyond\",\"both\",\"brief\",\"but\",\"by\",\"c\",\"c'mon\",\"c's\",\"came\",\"can\",\"can't\",\"cannot\",\"cant\",\"cause\",\"causes\",\"certain\",\"certainly\",\"changes\",\"clearly\",\"co\",\"com\",\"come\",\"comes\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"contain\",\"containing\",\"contains\",\"corresponding\",\"could\",\"couldn't\",\"course\",\"currently\",\"d\",\"definitely\",\"described\",\"despite\",\"did\",\"didn't\",\"different\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"done\",\"down\",\"downwards\",\"during\",\"e\",\"each\",\"edu\",\"eg\",\"eight\",\"either\",\"else\",\"elsewhere\",\"enough\",\"entirely\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"exactly\",\"example\",\"except\",\"f\",\"far\",\"few\",\"fifth\",\"first\",\"five\",\"followed\",\"following\",\"follows\",\"for\",\"former\",\"formerly\",\"forth\",\"four\",\"from\",\"further\",\"furthermore\",\"g\",\"get\",\"gets\",\"getting\",\"given\",\"gives\",\"go\",\"goes\",\"going\",\"gone\",\"got\",\"gotten\",\"greetings\",\"h\",\"had\",\"hadn't\",\"happens\",\"hardly\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he's\",\"hello\",\"help\",\"hence\",\"her\",\"here\",\"here's\",\"hereafter\",\"hereby\",\"herein\",\"hereupon\",\"hers\",\"herself\",\"hi\",\"him\",\"himself\",\"his\",\"hither\",\"hopefully\",\"how\",\"howbeit\",\"however\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"ie\",\"if\",\"ignored\",\"immediate\",\"in\",\"inasmuch\",\"inc\",\"indeed\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"instead\",\"into\",\"inward\",\"is\",\"isn't\",\"it\",\"it'd\",\"it'll\",\"it's\",\"its\",\"itself\",\"j\",\"just\",\"k\",\"keep\",\"keeps\",\"kept\",\"know\",\"known\",\"knows\",\"l\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"let's\",\"like\",\"liked\",\"likely\",\"little\",\"look\",\"looking\",\"looks\",\"ltd\",\"m\",\"mainly\",\"many\",\"may\",\"maybe\",\"me\",\"mean\",\"meanwhile\",\"merely\",\"might\",\"more\",\"moreover\",\"most\",\"mostly\",\"much\",\"must\",\"my\",\"myself\",\"n\",\"name\",\"namely\",\"nd\",\"near\",\"nearly\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"no\",\"nobody\",\"non\",\"none\",\"noone\",\"nor\",\"normally\",\"not\",\"nothing\",\"novel\",\"now\",\"nowhere\",\"o\",\"obviously\",\"of\",\"off\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"on\",\"once\",\"one\",\"ones\",\"only\",\"onto\",\"or\",\"other\",\"others\",\"otherwise\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"outside\",\"over\",\"overall\",\"own\",\"p\",\"particular\",\"particularly\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"possible\",\"presumably\",\"probably\",\"provides\",\"q\",\"que\",\"quite\",\"qv\",\"r\",\"rather\",\"rd\",\"re\",\"really\",\"reasonably\",\"regarding\",\"regardless\",\"regards\",\"relatively\",\"respectively\",\"right\",\"s\",\"said\",\"same\",\"saw\",\"say\",\"saying\",\"says\",\"second\",\"secondly\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sensible\",\"sent\",\"serious\",\"seriously\",\"seven\",\"several\",\"shall\",\"she\",\"should\",\"shouldn't\",\"since\",\"six\",\"so\",\"some\",\"somebody\",\"somehow\",\"someone\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specified\",\"specify\",\"specifying\",\"still\",\"sub\",\"such\",\"sup\",\"sure\",\"t\",\"t's\",\"take\",\"taken\",\"tell\",\"tends\",\"th\",\"than\",\"thank\",\"thanks\",\"thanx\",\"that\",\"that's\",\"thats\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"thence\",\"there\",\"there's\",\"thereafter\",\"thereby\",\"therefore\",\"therein\",\"theres\",\"thereupon\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"think\",\"third\",\"this\",\"thorough\",\"thoroughly\",\"those\",\"though\",\"three\",\"through\",\"throughout\",\"thru\",\"thus\",\"to\",\"together\",\"too\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"twice\",\"two\",\"u\",\"un\",\"under\",\"unfortunately\",\"unless\",\"unlikely\",\"until\",\"unto\",\"up\",\"upon\",\"us\",\"use\",\"used\",\"useful\",\"uses\",\"using\",\"usually\",\"uucp\",\"v\",\"value\",\"various\",\"very\",\"via\",\"viz\",\"vs\",\"w\",\"want\",\"wants\",\"was\",\"wasn't\",\"way\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"welcome\",\"well\",\"went\",\"were\",\"weren't\",\"what\",\"what's\",\"whatever\",\"when\",\"whence\",\"whenever\",\"where\",\"where's\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"whereupon\",\"wherever\",\"whether\",\"which\",\"while\",\"whither\",\"who\",\"who's\",\"whoever\",\"whole\",\"whom\",\"whose\",\"why\",\"will\",\"willing\",\"wish\",\"with\",\"within\",\"without\",\"won't\",\"wonder\",\"would\",\"wouldn't\",\"x\",\"y\",\"yes\",\"yet\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"z\",\"zero\"]}\n",
    "stopwords_json_en = set(stopwords_json['en'])\n",
    "stopwords_nltk_en = set(stopwords.words('english'))\n",
    "stopwords_punct = set(punctuation)\n",
    "# Combine the stopwords. Its a lot longer so I'm not printing it out...\n",
    "stoplist_combined = set.union(stopwords_json_en, stopwords_nltk_en, stopwords_punct)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    #returns the words if not a digit and not a stopword\n",
    "    return [word for word in lemmatize_sent(text) \n",
    "            if word not in stoplist_combined\n",
    "            and not word.isdigit()]\n",
    "\n",
    "def lemmatize_sent(text): \n",
    "    # tag a sentence and using the tag convert it into WordNet tagsets \n",
    "    # and then put it through to the WordNetLemmatizer.\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(word_tokenize(text))]#word_tokenize(text): splits sentences into words.\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    #Converts Penn Treebank tags to WordNet.\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]#only the first 2 letters of the tag matter\n",
    "    except:\n",
    "        return 'n' # if mapping isn't found, fall back to Noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4da693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer=preprocess_text)\n",
    "#object that contains the vocabulary\n",
    "#and has the function to convert any sentence into the counts vectors we see as above.\n",
    "\n",
    "train_set = count_vect.fit_transform(train['request_text_edit_aware'])\n",
    "y_train = train['requester_received_pizza']\n",
    "valid_set = count_vect.transform(valid['request_text_edit_aware'])\n",
    "y_valid = valid['requester_received_pizza']\n",
    "test_set = count_vect.transform(df_test['request_text_edit_aware'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c265e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3232, 9418), (3232,), (808, 9418), (808,), (1631, 9418))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape, y_train.shape, valid_set.shape, y_valid.shape,test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30f8f36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB() \n",
    "\n",
    "clf.fit(train_set, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2b21345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7339108910891089"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions_valid = clf.predict(valid_set)\n",
    "accuracy_score(predictions_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a9a735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now repeat without splitting the train set\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer=preprocess_text)\n",
    "\n",
    "train_set = count_vect.fit_transform(df_train['request_text_edit_aware'])\n",
    "y_train = df_train['requester_received_pizza']\n",
    "test_set = count_vect.transform(df_test['request_text_edit_aware'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "77a6e745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4040, 10755), (4040,), (1631, 10755))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape, y_train.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c7374a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB() \n",
    "\n",
    "clf.fit(train_set, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5493009a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8762376237623762"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_valid = clf.predict(valid_set)\n",
    "accuracy_score(predictions_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b00985b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03372164316370325"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions= clf.predict(test_set)\n",
    "success_rate = sum(predictions) / len(predictions)\n",
    "success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e3785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
